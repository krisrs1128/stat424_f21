---
title: "Fitting Random Effects"
description: |
  A short description of the post.
author:
  - name: Kris Sankaran
    url: {}
date: 08-03-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
library("knitr")
opts_chunk$set(cache = FALSE, message = FALSE, warning = FALSE, echo = TRUE)
```

_Readings [3.9](), [Rmarkdown]()_
https://docs.google.com/document/d/1OjgpajLhWmrbjB2PG52__QUYstWYvMFuIaU2aTiBh4c/edit

```{r}
include_graphics("https://uwmadison.box.com/shared/static/f2e3b39odm4ejkyqinvpii24s9tegnqb.png")
include_graphics("https://uwmadison.box.com/shared/static/ujmby14i61prsex43i6drsgpgsu9lvjq.png")
include_graphics("https://uwmadison.box.com/shared/static/0au3iwj17u49ueqor5djqg58rensvmqo.png")
include_graphics("https://uwmadison.box.com/shared/static/kqgsua08wh8n2h6zhssbmxf4byldcq2o.png")
```

There are three key parameters: , 2,2. 
Two ways to fit them are (1) the method of moments and (2) maximum likelihood.

Method of Moments

For estimating , this method uses the overall mean y.

What about the 2’s? The key identity is,


We can approximate the expected values through,



If we pretended these approximations were exact equalities, then we have two equations with two unknowns. The method of moments defines parameter estimates as the solutions to that system of equations.



How can we get confidence intervals for these estimates?

For =y, we can use Var(y)=1NVar(yij)=2+n2N
For 2, we can use the fact that (N - a)MSE22N - a
For 2, we’re out of luck, though some papers give approximate confidence intervals.

Maximum Likelihood Estimation

An alternative approach is to use maximum likelihood.

Stack all the yij’s into one long length N vector, and observe that the data are jointly normally distributed



The specific form of the covariance isn’t important. What is important is that we can exactly evaluate the probability of y11, y12,yan under any choice of the parameters , 2, 2. 

Define L(, 2, 2) the probability of the dataset  y11, y12,yanviewed as a function of the normal distribution’s parameters
A good estimate for these parameters comes from finding the configuration that maximizes L(, 2, 2).

The maximizers can’t be found analytically, but algorithms exist to find the maximizers
Software also gives a confidence interval for the estimates. It works by studying the curvature of the likelihood function at the maximizer, though we don’t need to worry about the details.


