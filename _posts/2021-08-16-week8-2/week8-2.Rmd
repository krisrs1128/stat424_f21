---
title: "Interpreting Effects in $2^2$ Designs"
description: |
  Drawing conclusions from parameter estimates.
author:
  - name: Kris Sankaran
    url: {}
date: 10-26-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache = FALSE, message = FALSE, warning = FALSE, echo = TRUE)
```

_Readings [6.2](https://www.wiley.com/en-us/Design+and+Analysis+of+Experiments%2C+10th+Edition-p-9781119492443#content-section), [Rmarkdown](https://github.com/krisrs1128/stat424_f21/blob/main/_posts/2021-08-16-week8-2/week8-2.Rmd)_

```{r}
library(ggplot2)
library(EBImage)
theme424 <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(theme424)
```

1. We will often want to know whether estimated main or interaction effects are
significant. We can use ANOVA, though we have to be cautious when $n$ is small.
    * The numerators in the effect estimate expressions will be called _contrasts_
    for the estimated effect
    * For example, the contrast for the effect of $A$ is $ab + a - b -
    \left(1\right)$.
    
2. The associated sum of squares is
    $$
    \frac{1}{2^2 n}\left(\text{Contrast}\right)^2
    $$
    for example,
    $$
    SS_A = \frac{1}{2^2 n}\left[ab + a - b - (1)\right]^2
    $$
    
3. The associated ANOVA decomposition is
    $$
    SS_{\text{Total}} = SS_A + SS_B + SS_{AB} + SS_E
    $$
    and since the factors all have two levels, the df’s for the main and interaction
    terms are all 1. The df of $SS_T$ is $n 2^2 - 1$ (number of samples minus one).
    Taking the ratio between main and interaction $SS$ terms and $SS_E$ gives the
    basis for F-statistics in the ANOVA table.

### Regression View

4. Another way of summarizing the $2^2$ model is to write a regression,
$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon
$$
where the $x_k$’s take on one of two values, depending on whether or not factor $k$ is active.

```{r, fig.margin = TRUE}
display(readImage("https://uwmadison.box.com/shared/static/giacopxkfj5jhuucepards9fv0cqvbmc.png"))
```

    * We’ve only included main effects. An interaction would be added via $\beta_{12} x_{1}x_{2}$
    * If the factors are binary (on vs. off), we can use a binary encoding. 

5. What if our factors are actually continuous?
	* We could _code_ the variables, converting low and high levels to ${-1, 1}$.
	* The model will still apply to all values in interval $[-1, 1]$.
	* An added benefit is that this coding (a) makes scales comparable and (b)
	induces orthogonality (roughly, it makes variables less correlated)
	
```{r}
library(dplyr)
library(readr)
yield <- read_table2("https://uwmadison.box.com/shared/static/bfwd6us8xsii4uelzftg1azu2f7z77mk.txt") %>%
  mutate_at(vars(-Yield), as.factor)
```

```{r}
coded <- function(x) ifelse(x == '-', -1, 1)
yield <- yield %>%
  mutate(cA = coded(A), cB = coded(B))
fit <- lm(Yield ~ cA * cB, data = yield)
summary(fit)
summary(aov(fit))
```
	
6. We can use this fit to build a response surface as well.

```{r}
library(rsm)
coef(fit)
image(fit, ~ cA + cB)
```
 