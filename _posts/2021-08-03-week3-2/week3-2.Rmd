---
title: "Model Checking"
description: |
  A short description of the post.
author:
  - name: Kris Sankaran
    url: {}
date: 08-03-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
library("knitr")
opts_chunk$set(cache = FALSE, message = FALSE, warning = FALSE, echo = TRUE)
```

_Readings [3.4](), [Rmarkdown]()_

https://docs.google.com/document/d/1Ds7H3hZyqLNYhF8wQ2OZO7viJuHd74EzYNSXjrTH6eU/edit

https://uwmadison.box.com/shared/static/ka2t5b3awtqt0mqdqtm8o5zbzs8ur7xp.png

Assumptions

Recall the ANOVA model,



with independent errors ijN(0, 2). There are a few ways that this model can fail,
There might be systematic variations besides the group deviations i.
The errors might not be normally distributed
The errors might not be independent
The variance might not be the same in each group

To see if the model is okay, it will be helpful to define residuals,

.
Residuals are our best guess of what the true random error ij is like.
Normal Probability Plots

We can’t check normality of ijdirectly, but we can check normality of the residuals eij using normal probability plots.

In the plot to the right, it looks like the data are somewhat more tightly clustered near the middle, though the most extreme points are more extreme than expected. Do you see why?

Of the ways that the model can fail, normality of the residuals is not the most severe, because you can often count on the central limit theorem to make the reference F distribution still approximately correct.
Plotting Residuals
The way to check for systematic variation beyond the i’s, try plotting residuals against measured variables. If you see “patterns”, those represent missing terms in your model.
Use plots to check for independence. For example, if you plot the residuals over time and you see clear trends, then the errors are likely correlated over time.
Plotting residuals against the fitted values. This can reveal nonconstant variance across the groups.
Testing Equality of Variances
There are formal tests to test whether the equal variance assumption of the ANOVA is valid (it’s sort of meta). The most common are,
Bartlett’s test
The Modified Levene test
The main difference is that the Modified Levene test is still valid even when the errors are not normally distributed. You don’t need to memorize the test statistics, but know that they exist, and be able to interpret associated computer output.
Transformations
What can you do if you detect nonconstant variance across groups? The most common fix is to use a variance stabilizing transformation. That is, apply some function f(x) to each data point and then perform the ANOVA.

 There are various rules of thumb, though the process is still somewhat informal,
f(x) =x or f(x) =1 + x If your data seem Poisson
f(x) =(x): If your data seem lognormal
f(x) =(x ): If your data are binomial in fraction form

These are special cases. More generally, if you notice , then setting f(x) = x1 - will stabilize the variance.

(It’s not at all obvious why any of these transformations are effective -- they are typically derived in introductory mathematical statistics courses).
