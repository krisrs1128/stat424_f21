---
title: An Introduction to Response Surfaces
description: |
  Flexibly modeling the relationship between factors and a response.
author:
  - name: Kris Sankaran
    url: {}
date: 10-21-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache = FALSE, message = FALSE, warning = FALSE, echo = TRUE)
```

_Readings [5.5](https://www.wiley.com/en-us/Design+and+Analysis+of+Experiments%2C+10th+Edition-p-9781119492443#content-section), [Rmarkdown](https://github.com/krisrs1128/stat424_f21/blob/main/_posts/2021-08-16-week7-4/week7-4.Rmd)_

```{r, echo = FALSE}
library(ggplot2)
theme424 <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(theme424)
```

1. We’ve really pushed a particular recipe for all our hypothesis testing
approaches,
    * Write down a model with various factor level effects
    * Write down a sum-of-squares identity, and get the corresponding
    degrees-of-freedom
    * Get a test statistic and its reference distribution, for testing each factor
We’ve used this in ANOVA, RCBD, general factorial designs…

2. We’re now going to introduce a quite different approach based on response
surfaces. The idea is simple: use a flexible (nonlinear) function from
experimental inputs (combinations of factor levels) to the response of interest.
This will work as long as the response varies smoothly as factor inputs are
perturbed. The estimated function will be a good representation of how varying
the factors affects the response.

3. Moreover, if we have successfully estimated this function, then we’ll be able
to use the fit to (a) determine important influences and (b) find configurations
that optimize the response (e.g., maximize profit[^Or if you are disgruntled,
minimize profit]).

4. How should we fit these flexible functions?
    * Polynomial regression: include terms like $x_i^2, x_i^3, x_i^2 x_j, ...$
    * Spline regression: Include polynomial terms, but split across different
    regions of the input space. This is generally more stable than polynomial
    regression.
    * Really, you can use whatever function fitter that you want.
Unfortunately, this idea will have to wait till near the end of the course for a
more complete elaboration.

## Data Example

5. Let's look at this idea using the battery data from before. We'll treat
temperature as a continuous variable, so that it makes sense to talk about a
response surface[^really, a curve over temperature].

```{r}
library(dplyr)
library(readr)
battery <- read_table2("https://uwmadison.box.com/shared/static/vmxs2wcsdxkdjujp85nw5kvk83xz4gl9.txt") %>%
  mutate(Material = as.factor(Material))
```

6. We fit a quadratic regression to define the surface. The result let's us make
predictions for battery life at temperatures that we haven't observed. First, we
fit a model that uses both `Material` and a quadratic expansion of `Temperature`.

```{r}
fit <- lm(Life ~ Material * poly(Temperature, 2), data = battery)
```

  To visualize the response surface, we compute predictions across a find grid
  of temperature values for each material.

```{r}
surface <- expand.grid(
  Temperature = seq(15, 125, by = 1),
  Material = unique(battery$Material) 
  )
surface$Life <- predict(fit, surface)

ggplot(battery, aes(Temperature, Life)) +
  geom_point() +
  geom_line(data = surface) +
  facet_wrap(~ Material)
```

7. Compare the associated fit with Table 5.15.

```{r}
summary(fit)
```