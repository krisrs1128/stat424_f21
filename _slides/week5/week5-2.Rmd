---
title: "RCBD with Random Blocks and Latin Squares"
author: "Kris Sankaran | UW Madison | 7 October 2021"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    seal: false  
---

```{r setup, include=FALSE}
library(knitr)
library(ggplot2)
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, dpi = 200, fig.width = 6, fig.height = 2.7, dev = 'svg', dev.args = list(bg = "transparent"))
theme424 <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(theme424)
```

# RCBD with Random Blocks + Latin Squares

```{r, out.width = 300}
include_graphics("https://uwmadison.box.com/shared/static/gu58jurmhyraebsdyh4txlpyxegxn9xf.png")
```

### Statistical Experimental Design

.large[Kris Sankaran | UW Madison | 7 October 2021]

---

### Today

* Book Sections: 4.1 - 4.3
* Online Notes: Week 5 [3], [4], [5]

---

### Warm-Up: Memo to Friend

Imagine that your friend missed the last lecture. Work with a partner to draft a
short summary of one key idea or piece of code discussed in the last lecture.
Have either you or your partner submit your memo to on Canvas (Week 5 -
Discussion 2).

---

### Motivation

Though useful, Randomized Complete Block Designs cannot be applied in a variety
of realistic settings,
1. If there are many blocks, estimation becomes cumbersome
2. There might be more than one source of nuisance variation
3. The number of samples per batch must equal the number of treatments

---

### Overview

This lecture $\rightarrow 1, 2$. Next week $\rightarrow 3$.

1. Working with many blocks $\rightarrow$ RCBD with Random Block Effects
2. Multiple sources of nuisance variation $\rightarrow$ Latin Squares
3. Fewer samples than treatments $\rightarrow$ Incomplete Block Designs

---

### RCBD with Random Blocks

.center[
ANOVA $\rightarrow$ Random Effects ANOVA

RCBD $\rightarrow$ RCBD with Random Block Effects
]

* ANOVA with Random Effects: Imagine that **group effects** are drawn from a
large population.
* RCBD with Random Block Effects: Imagine that **block effects** are drawn from
a large population.

---

### Model

.pull-left[
* Block effects $\beta_{j}$ are imagined to be drawn from a large population of
effects.
* Treatment effects $\tau_i$ are still fixed parameters.

\begin{align}
y_{ij} &= \mu + \tau_i + \beta_j + \epsilon_{ij} \\
\beta_{j} &\sim \mathcal{N}\left(0, \sigma_{\beta}^2\right) \\
\epsilon_{ij} &\sim \mathcal{N}\left(0, \sigma^2\right)
\end{align}
]

.pull-right[
```{r, out.width = 350}
include_graphics("https://uwmadison.box.com/shared/static/gu58jurmhyraebsdyh4txlpyxegxn9xf.png")
```
]

---

### Hypothesis Testing

The test of interest (and its interpretation) are exactly the same as for
ordinary RCBDs.

\begin{align*}
H_0 &: \tau_1 = \dots = \tau_a = 0 \\
H_{1} &: \tau_{i} \neq 0 \text{ for at least one } i
\end{align*}

In fact, we can use the same test statistic $\frac{MS_{\text{Treatment}}}{MS_{E}}$ and cutoffs as in the fixed block case.

---

### Latin Squares

Imagine there are two sources of nuisance variation in an experiment,

  * We’re testing a manufacturing procedure, but raw materials come in batches
  and different operators have different skills.
  * We’re testing different diets on cows over a series of days, but there will
  both cow and day effects.

---

### Intuition

> Make sure to run each treatment on each nuisance factor exactly once.

  * Each operator should see each treatment once, and each batch of materials
  should be used for each treatment
  * Don't want any particular treatment to get lucky and have a "good" batch of
  material or operator

---

### Setup

Latin Squares are $p\times p$ arrays, filled with $p$ letters, so that each
letter appears exactly once in each row and each column.
  
|   |   |   |
| - | - | - |
| A | B | C |
| B | C | A |
| C | A | B |

It is like Sudoku.

---

### Recipe

* The rows are levels of the first blocking factor.
* The columns are levels of the second blocking factor.
* The letters are the treatment levels

Then, the experiment consists of $p^2$ runs, one for each of the pairs of
blocking levels, with treatment specified by the cell’s label

---

### Model

We now have two sets of block effects, $\alpha_i$ and $\beta_k$.

\begin{align*}
y_{ijk} &= \mu + \alpha_i + \tau_j + \beta_k + \epsilon_{ijk} \\
\epsilon_{ijk} &\sim \mathcal{N}\left(0,\sigma^2\right)
\end{align*}

Note that each of the indices $i, j$ and $k$ range from $1, \dots, p$.

---

### Hypothesis Testing

We are still interested in the same hypothesis test, though now we are
controlling for two sources of nuisance variation.

\begin{align*}
H_0 &: \tau_1 = \dots = \tau_a = 0 \\
H_{1} &: \tau_{i} \neq 0 \text{ for at least one } i
\end{align*}

---

### ANOVA-like Identity

.pull-left[
\begin{align*}
SS_{\text{Total}} = &SS_{\text{Rows}} + \\
&SS_{\text{Columns}} +\\
&SS_{\text{Treatment}} + \\
&SS_{E}
\end{align*}
]

.pull-right[
In analogy to ANOVA, define
* $MS_{\text{Rows}}=\frac{1}{p - 1}SS_{\text{Rows}}$
* $MS_{\text{Treatment}}=\frac{1}{p - 1}SS_{\text{Treatment}}$
* $MS_{\text{Columns}}=\frac{1}{p - 1}SS_{\text{Columns}}$
* $MS_{E}=\frac{1}{(p - 1)(p - 2)}SS_{E}$
]

---

### Hypothesis Testing

Under the null hypothesis, it can be shown that,

\begin{align*}
\frac{MS_{\text{Treatment}}}{MS_{E}} \sim F\left(p - 1, \left(p - 1\right)\left(p - 2\right)\right)
\end{align*}

Therefore, we reject the null if the ratio lies above the $1 - \alpha$ quantile
of this $F$-distribution.

---

# Code Implementation

Take out your laptops!

```{r}
opts_chunk$set(echo = TRUE)
```


---

### RCBD with Random Blocks

We will reanalyze the graft dataset, but treating the batches as random samples
from a larger population.

```{r}
library(readr)
library(tidyr)
graft <- read_table2("https://uwmadison.box.com/shared/static/0ciblk4z2f3k6zizbj4plg3q33w1d0n6.txt") %>%
  pivot_longer(-Pressure, names_to = "batch", values_to = "yield")
graft$Pressure <- as.factor(graft$Pressure)
```

---

.pull-left[
* We can continue to use the `lmer` function from `lme4`.
* `(1 | variable)` indicates that a variable should be treated as random
* We estimate a fixed effect for `Pressure` but a random effect for `batch` 
]

.pull-right[
```{r}
library(lme4)
fit <- lmer(yield ~ Pressure + (1 | batch), data = graft)
fit
```
]

---

### Confidence Intervals

We can compute confidence intervals using the same `confint` function as before.

```{r}
confint(fit)
```

---

### Latin Squares

.pull-left[
* In the rocket dataset, both operator and batch are nuisance factors
* The `mutate_at` line is a shortcut to using `as.factor` for the `Batch`,
`Operator`, and `Formulation` columns
]

.pull-right[
```{r}
library(dplyr)
rocket <- read_table2("https://uwmadison.box.com/shared/static/ac68766l3zcjog1ldrzki3lis74bbd71.txt") %>%
  mutate_at(vars(-BurningRate), as.factor) # convert all but BurningRate to factor
head(rocket)
```
]

---

### Hypothesis Test

* We can use `lm` to fit the Latin Squares model
* The `.` notation is a shortcut for including a term for every column

```{r}
#fit <- lm(BurningRate ~ Batch + Operator + Formulation, data = rocket) # gives exact same result
fit <- lm(BurningRate ~ ., data = rocket)
```

---

### Hypothesis Test

.pull-left[
* There is an operator effect, but no detectable variation across batches.
* Controlling for batch and operator, there is a significant difference across
formulations.
]

.pull-right[
```{r}
summary(aov(fit))
```
]

---
class: small

### Exercise

This walks through Problem 4.24 in the textbook.

.pull-left[
The effect of five different ingredients $(A, B, C, D, E)$ on the reaction time
of a chemical process is being studied. Each batch of new material is only large
enough to permit five runs to be made. Furthermore, each run requires
approximately 1.5 hours, so only 5 runs can be made in one day. The experimenter
decides to run the experiment as a Latin square so that the day and batch
effects may be systematically controlled. She obtains the data that follow.
Analyze the data from this experiment (use $\alpha = 0.05$) and draw
conclusions.
]

.pull-right[
```{r}
library(dplyr)
experiment <- data.frame(
  day = rep(1:5, each = 5),
  batch = rep(1:5, 5),
  ingredient = c("A", "C", "B", "D", "E", "B", "E", "A", "C", "D", "D", "A", "C", "E", "B", "C", "D", "E", "B", "A", "E", "B", "D", "A", "C"),
  time = c(8, 11, 4, 6, 4, 7, 2, 9, 8, 2, 1, 7, 10, 6, 3, 7, 3, 1, 6, 8, 3, 8, 5, 10, 8)
) %>%
  mutate_at(vars(-time), as.factor) # why is this needed?
```
]

---
  
(1) Summarize the problem statement in one sentence.

(2) Setup a formula for `lm` that fits the ingredient effect while controlling
for batch and day.

(3) Use `lm` and `aov` to produce an ANOVA table. Interpret the $p$-value for
the ingredient effect in context.
  
Bonus: Are there systematic differences in the model's residuals across batches
or days? What are the implications?

---

### Solution (1)

A Latin squares experiment was run to see how ingredient affects reaction time
in a plant, controlling for two sources of nuisance variation (batch and day).

---

### Solution (2)

 * We can use  `time ~ ingredient + batch + day`.
 * This can be abbreviated `time ~ .`, since the right hand side contains
 all columns in the `data.frame` other than time.

---

### Solution (3)

```{r}
fit <- lm(time ~ ingredient + batch + day, data = experiment)
summary(aov(fit))
```

After controlling for the sources of potential nuisance variation, there is a
very strong ingredient effect. We can conclude that the ingredients are not all identical.

---

### Solution: Bonus

.pull-left[Normality seems plausible, and there are no systematic differences between
batches. However, some of the days seemed to have higher variance than others.
It might be worth transforming the response to stabilize the variance.
]

.pull-right[
```{r}
experiment <- experiment %>%
  mutate(
    residual = resid(fit),
    fitted = predict(fit)
    )
```
]

---

### Solution: Bonus

.pull-left[Normality seems plausible, and there are no systematic differences between
batches. However, some of the days seemed to have higher variance than others.
It might be worth transforming the response to stabilize the variance.
]

.pull-right[
```{r, fig.width = 4, fig.height = 2.6}
library(ggbeeswarm)
ggplot(experiment) +
  geom_beeswarm(aes(batch, residual))
```
]

---

### Solution: Bonus

.pull-left[Normality seems plausible, and there are no systematic differences between
batches. However, some of the days seemed to have higher variance than others.
It might be worth transforming the response to stabilize the variance.
]

.pull-right[
```{r, fig.width = 4, fig.height = 2.6}
ggplot(experiment) +
  geom_beeswarm(aes(day, residual))
```
]
