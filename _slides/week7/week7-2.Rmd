---
title: "$K$ Factor Factorials and Basic Response Surfaces"
author: "Kris Sankaran | UW Madison | 23 September 2021"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    seal: false  
---

```{r setup, echo=FALSE}
library(knitr)
library(ggplot2)
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, dpi = 200, fig.width = 6, fig.height = 2.8, dev = 'svg', dev.args = list(bg = "transparent"))
theme424 <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    strip.text = element_text(size = 14),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.position = "bottom"
  )
theme_set(theme424)
```

# $K$ Factor Factorials and Basic Response Surfaces

```{r, out.width = 310}
include_graphics("https://uwmadison.box.com/shared/static/b42kbwxdggtmf2krqr7uoj5r23fglfuo.png")
```
### Statistical Experimental Design

.large[Kris Sankaran | UW Madison | 21 October 2021]

---

### Today

* Book Sections: 5.4 - 5.5
* Online Notes: Week 7 [3] and [4]

---

### Motivation: $K$ Factor Designs

* We have only analyzed two factors at a time, but the ideas generalize
  - We provide the details today
* We will often be interested in many effects and their interactions

---

### Three Factor Model

To characterize $K$ factor models, we'll first examine symmetries in the 3
factor model.

\begin{align*}
y_{ijkl} &= \mu + \tau_i + \beta_j + \gamma_k + \left(\tau \beta\right)_{ij} + \left(\tau \gamma\right)_{ik} + \left(\beta \gamma\right)_{jk} + \left(\tau \beta \gamma\right)_{ijk} + \epsilon_{ijkl} \\
\epsilon_{ijkl}&\overset{i.i.d.}{\sim}\mathcal{N}\left(0, \sigma^2\right)
\end{align*}

---

### Symmetry

.pull-left[
* **We have main effects for each factor $\tau_i, \beta_j, \gamma_k$**
* We have two-way interactions for pairs of factors $\left(\tau\beta\right)_{ij}, \dots$
* We have a three-way interaction between all factors $\left(\tau\beta\gamma\right)_{ijk}$
]

.pull-right[
```{r, fig.margin = TRUE, echo = FALSE}
include_graphics("https://uwmadison.box.com/shared/static/b42kbwxdggtmf2krqr7uoj5r23fglfuo.png")
```
]
    
---

### Symmetry

.pull-left[
* We have main effects for each factor $\tau_i, \beta_j, \gamma_k$
* **We have two-way interactions for pairs of factors $\left(\tau\beta\right)_{ij}, \dots$**
* We have a three-way interaction between all factors $\left(\tau\beta\gamma\right)_{ijk}$
]

.pull-right[
```{r}
include_graphics("https://uwmadison.box.com/shared/static/gnoa5i4w5qp6ehbweh30n3a2v91qpi89.png")
```
]
    
---

### Symmetry

.pull-left[
* We have main effects for each factor $\tau_i, \beta_j, \gamma_k$
* **We have two-way interactions for pairs of factors $\left(\tau\beta\right)_{ij}, \dots$**
* We have a three-way interaction between all factors $\left(\tau\beta\gamma\right)_{ijk}$
]

.pull-right[
```{r}
include_graphics("https://uwmadison.box.com/shared/static/yqqhfc2kzk3egfvad8dvufed09t9m3tx.png")
```
]
    
---

### Symmetry

.pull-left[
* We have main effects for each factor $\tau_i, \beta_j, \gamma_k$
* We have two-way interactions for pairs of factors $\left(\tau\beta\right)_{ij}, \dots$
* **We have a three-way interaction between all factors $\left(\tau\beta\gamma\right)_{ijk}$**
]

.pull-right[
```{r, fig.margin = TRUE, echo = FALSE}
include_graphics("https://uwmadison.box.com/shared/static/goaewwcs61ewtrmfp4pcymzje1fdrbsb.png")
```
]
    
---

### Sums of Squares

We can calculate sum-of-squares terms for each of the terms
- Main effects: Group averages minus global averages
- Interaction effects: Configuration averages minus main effect fits

\begin{align*}
\text{Example main effect sum: } &\sum_{i}\left(\bar{y}_{i . .}-\bar{y}\right)^{2}\\
\text{Example interaction sum: } & \sum_{i, j}\left(\bar{y}_{i j.}-\bar{y}_{i. .}+\bar{y}_{. j.}-\bar{y}\right)^{2}
\end{align*}

---

### Degrees of Freedom

There is also symmetry in the degrees of freedom,

  * $SS_A = a - 1$
  * $SS_B = b - 1$
  * $SS_C = c - 1$
  * $SS_{AB} = (a - 1)(b - 1)$
  * $SS_{BC} = (b - 1)(c - 1)$
  * ...
  * $SS_{ABC} = (a - 1)(b - 1)(c - 1)$

By subtraction, $SS_{E}$ has $abc\left(n - 1\right)$ degrees of freedom.
    
Q: What do you think is the pattern for arbitrary $K$.

---

### Test Statistics

* We can construct an $MS$ term by dividing the $SS$ term by its d.f.
* We can test the null by comparing these $MS$ terms with $MS_{E}$
* Each of these statistics is $F$-distributed under the null, with appropriate
d.f. (numerator from previous slide, denominator always $abc\left(n - 1\right)$)

---

# Code Implementation

```{r, echo = FALSE}
opts_chunk$set(echo = TRUE)
options(width = 500)
```


---

### $2^3$ Design

We'll study an experiment testing how etch rate on a chip varies as we change
(A) gap between electrodes, (B) power level, and (C) gas flow rate. `+` and `-`
denote whether the factor is at a low or high level.

```{r}
plasma <- read.table("https://uwmadison.box.com/shared/static/f3sggiltyl5ycw1gu1vq7uv7omp4pjdg.txt", header=TRUE)
head(plasma)
```

---

### Visualization

.pull-left[
* `facet_grid` lets us split the plot into panels depending on each factor
* There seems to be a strong interaction effect between A and C
  - The slope of the effect of A switches when we change C
 ] 

.pull-right[
```{r, out.width = 500}
library(ggplot2)
ggplot(plasma) +
  geom_point(aes(A, Rate)) +
  facet_grid(B ~ C)
```
]

---

### ANOVA Table

* The ANOVA table computes $SS$ and $MS$ terms associated with the model
* Changing the power level doesn't make much of a difference. The gas flow rate
is very important, and the gap between electrodes also has an effect. We have
also detected the interaction seen in the plot.


```{r}
fit <- lm(Rate ~ A * B * C, plasma)
summary(aov(fit))
```

---

### Discussion (3 - 2 - 1)

Working with a partner, discuss

* 3 things you learned
* 2 things you found interesting
* 1 thing you are confused about

from the lecture so far?

---

# Response Surfaces

```{r, echo = FALSE}
opts_chunk$set(echo = FALSE)
```

```{r, fig.align = "left", out.width = 600}
include_graphics("https://uwmadison.box.com/shared/static/uubzanl5c273c45mxazy0d06r7r0uz52.png")
```

---

### Motivation: Response Surfaces

* We have implicitly assumed all factors are linearly related to the response
  - We'll discuss response surfaces, which remove this assumption
* Factor effects might saturate eventually (e.g., drug dosage, online ads)

---


### Response Surfaces

* All the models so far treat the levels of a factor as categorical
  - Each group gets its own parameter, and we do not share information across
  groups
* If we expect nearby levels of a factor to give similar experimental outputs, then
  - The response is a smooth function of inputs
  - We should borrow evidence from nearby levels

> Main Idea: Use a flexible (nonlinear) function from experimental inputs (combinations of factor levels) to the response of interest.

---

### Uses of Response Surfaces

The response surface is a representation of how varying the factors changes the
response. This is helpful for,

* Determining important influences 
* Finding configurations that optimize the response

---

### Fitting Flexible Functions

* Polynomial regression: Has terms like $x_i^2, x_i^3, x_i^2 x_j, ...$
* Spline regression: Has polynomial terms, but defined locally
  - More stable than polynomial regression.

---

# Code Implementation

```{r}
opts_chunk$set(echo = TRUE)
```

---

### Response Surfaces

We'll work with the battery data that we've used before. Instead of treating
each temperature level as a separate group, we'll imagine that the battery
lifetime varies smoothly as a function of temperature.

```{r}
library(readr)
battery <- read_table2("https://uwmadison.box.com/shared/static/vmxs2wcsdxkdjujp85nw5kvk83xz4gl9.txt")
battery$Material <- as.factor(battery$Material)
head(battery, 4)
```

---

### Flexible Functions

* We continue to use `lm` to build a model from the predictors to the response
* We use `poly` or `ns` to create polynomial or natural spline functions of a continuous variable
* `Material * poly(Temperature, 2)` means we fit separate polynomials for each material
  - It is the analog of fitting both main and interaction effects

```{r}
fit <- lm(Life ~ Material * poly(Temperature, 2), data = battery) # quadratic polynomial

#library(splines) # for quadratic natural spline
#fit <- lm(Life ~ Material * ns(Temperature, 2), data = battery)
```

---

### Visualizing the Surface

* To visualize the full surface, compute the response value along a fine grid
* To create a grid, we can use `seq` to create a sequence and `expand.grid` to build the cross-product
* The second argument of `predict` tells where to evaluate the model

```{r}
surface <- expand.grid(Temperature = seq(15, 125, by = 1), Material = unique(battery$Material))
surface$Life <- predict(fit, surface)
```

---

### Visualizing the Surface

.pull-left[
* We can use `ggplot` to layer on both the raw data and the fitted surface
* `geom_point` plots the raw data, in the `battery` data.frame
* `geom_line` plots the fitted surface, computed in the previous slide
]

.pull-right[
```{r}
ggplot(battery, aes(Temperature, Life)) +
  geom_point() +
  geom_line(data = surface) +
  facet_wrap(~ Material)
```
]

---

### Exercise

This walks through problem 5.26.

An article describes a study on polysilicon doping. The data are available
[here](https://tinyurl.com/wh34yrp6). The response variable is base current.

* Prepare graphical displays to interpret this experiment.
* Is the model 

\begin{align*}
y = \beta + \beta_1 x_1 + \beta_2 x_2 + \beta_{22}x_2^2 + \beta_{12}x_{1}x_{2} + \epsilon
\end{align*}

supported by this experiment, where $x_1$ is doping level and $x_{2}$ is temperature?
Estimate the parameters in this model and plot the response surface.

---

(1) Read the data in from the link (https://tinyurl.com/wh34yrp6) and convert
`polysilicon` into a factor.

(2) Design and create a plot of the raw data. Ensure that the effects of both
factors are visible.

(3) Using `lm` and `poly`, fit the model specified in the problem statement.
Make sure to include the interaction term using `*`.

(4) Create a grid of temperature values for each polysilicon type using
`expand.grid` with `seq`.

(5) Evaluate the fitted model on the grid from (4), and plot the resulting
response surface.

---

### Solution (1)

```{r}
library(readr)
experiment <- read_csv("https://tinyurl.com/wh34yrp6") %>%
  mutate(polysilicon = as.factor(polysilicon))
```

---

### Solution (2)

There are many possible plots, but here is one approach. The gradual leveling
off of the current suggests a quadratic model.

```{r}
ggplot(experiment, aes(temperature, current, col = polysilicon)) +
  geom_point()
```

---

### Solution (3)

```{r}
fit <- lm(current ~ polysilicon * poly(temperature, 2), experiment)
summary(fit)
```

---

### Solution (4)

```{r}
grid <- expand.grid(polysilicon = c("1", "2"), temperature = seq(900, 1000, 10))
head(grid)
```

---

### Solution (5)

The quadratic model seems like a very good fit to the observed data.

```{r}
grid$current <- predict(fit, grid)
ggplot(experiment, aes(temperature, current, col = polysilicon)) +
  geom_line(data = grid) +
  geom_point()
```
