---
title: "Response Surfaces"
author: "Kris Sankaran | UW Madison"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    seal: false  
---

```{r setup, echo=FALSE}
library(knitr)
library(ggplot2)
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.width = 6, fig.height = 4, dev = 'svg', dev.args = list(bg = "transparent"), fig.align = "left")
theme424 <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(theme424)
```

# Response Surfaces I

```{r, out.width = 300, fig.align = "left"}
include_graphics("https://uwmadison.box.com/shared/static/uubzanl5c273c45mxazy0d06r7r0uz52.png")
```
### Statistical Experimental Design

.large[Kris Sankaran | UW Madison ]

---

### Today

* Book Sections: 11.1 - 11.3
* Online Notes: Week 12 [1] and [2]

---

### Motivation

* Earlier, we saw response surfaces as a way to fit nonlinear responses across a
set of factors
* The real power of the design comes in sequential settings, where we are
allowed a sequence of experiments to choose a configuration that works best

---

### Examples

* Historically, sequential experiments emerged when experimental design was
applied to manufacturing and engineering processes (as opposed to agriculture)
  - These settings allow much more rapid experimentation
* Modern examples
  - Optimizing battery manufacture for electric vehicles
  - Optimizing available inventory in a clothing manufacturing process
  - Improving user engagement metrics in an online setting
* In each case, we may start with a factorial experiment that is quite far from
the optimal one, but over a sequence of experiments, we might converge on a good
configuration

---

### Two Phases of Experimentation

.pull-left[
In sequential response surfaces, we divide up the design into to phases,
* First Order Phase: Use cheap (low sample) designs to find a good direction to
move towards.
* Second Order Phase: Once in the vicinity of an optimum, use expensive (sample
rich)  designs to find the best configuration.
]

.pull-right[
```{r, fig.cap = "In initial runs we will use first-order models. When we approach a potential optimum, we will switch to second-order models."}
include_graphics("https://uwmadison.box.com/shared/static/uubzanl5c273c45mxazy0d06r7r0uz52.png")
```
]

---

### Two Phases of Experimentation

.pull-left[
In sequential response surfaces, we divide up the design into to phases,
* First Order Phase: Use a model without any interaction terms or nonlinearities
move towards.
* Second Order Phase: Use a model with both interaction terms and nonlinearities
]

.pull-right[
```{r, fig.cap = "In initial runs we will use first-order models. When we approach a potential optimum, we will switch to second-order models."}
include_graphics("https://uwmadison.box.com/shared/static/uubzanl5c273c45mxazy0d06r7r0uz52.png")
```
]

---

###  First Order Model

$$\begin{align*}y_{i} &= \beta_{0} + \sum_{k = 1}^{K}x_{ik}\beta_{k} + \epsilon_{i} \\ 
&=: x_{i}^{T}b + \epsilon_{i}\end{align*}$$

Notice that this design doesn't require many samples. It can be fit even with an
unreplicated $2^{K}$ or $2^{K - p}$ design.

---

### Method of Steepest Ascent

.pull-left[
* Suppose we have fit a first order model to a particular factor configuration
* How do we know which direction to move in?
  - Which new factor configuration will bring us closer to the optimum?
* Main idea: Move a stepsize $\Delta$ that moves us in the steepest direction up
the fitted plane
]

.pull-right[
```{r fig.cap = "First order models have no isolated optima."}
include_graphics("https://uwmadison.box.com/shared/static/oi55vfta5tpd7foy8ur3lzt6gq5fkjfn.png")
```
]

---

### Method of Steepest Ascent

.pull-left[
* Suppose the current fitted surface has the form
$$\begin{align*}
\hat{y}\left(x\right) &= x^{T}\hat{b}
\end{align*}$$
* Find the coordinate $k^{\ast}$ satisfying,
$$\begin{align*}
	k^{\ast} &= \arg \max_{k \in \{1, \dots, K\}} \left|\hat{\beta}_{k}\right|
\end{align*}$$
  This is the factor to which the response is most sensitive. 
]

.pull-right[
* Define a stepsize $\Delta x_{k^{\ast}}$ for this particular factor
  - Make sure it's not so large that the fitted approximation is poor
* Update each factorâ€™s sampling values according to the sensitivities
  $\hat{\beta_{k}}$ of the response to that factor,
$$\begin{align*}
x \leftarrow x + \frac{\Delta x_{k^{\ast}}}{\beta_{k^{\ast}}} b
\end{align*}$$
]

---

### Second Order Model

Once we're in the vicinity of an optimum, we can fit a second order model,

\begin{align*}
y_{i} &= \beta_0 + \sum_{k = 1}^{K}\beta_{kk}x_{ik}^{2} + \sum_{k < k_{\prime}} \beta_{k k^{\prime}} x_{ik}x_{ik^{\prime}} + \epsilon_{i} \\
&= x_{i}^{T}b + x_{i}^{T} B x_i + \epsilon_{i},
\end{align*}

where we defined $B$ as the symmetric $K \times K$ matrix with diagonal entries
$\beta_{kk}$ and off-diagonal elements $\frac{1}{2}\beta_{kl} = \frac{1}{2}\beta_{lk}$.

Since this model fits a more complex surface, more samples are needed. We will
discuss specific designs for it in the next lecture.

---

### Canonical Analysis: Motivation

Once we fit a second order model, we should ask,
* Do we have enough information to decide on an optimal configuration? If so,
where is it?
* If we are still far from an optimal value, in which direction should we move?

Canonical analysis helps answer both of these questions.

---

### Characterizing optima

.pull-left[
* After fitting a second order model, we should decide whether we are in a local
minimum, maximum, or a saddlepoint
* In single-variable calculus, we would use the second-derivative test
]

.pull-right[
```{r fig.cap = "Second order model with a local minimum and at a saddlepoint.", fig.show = "hold", out.width = 250}
include_graphics("https://uwmadison.box.com/shared/static/qn1f8hrbb8uwtbflv02axa817m6tcmb7.png")
include_graphics("https://uwmadison.box.com/shared/static/x81swx5xslpzziywsupkuwpkyfggagis.png")
```
]
---

### Canonical Analysis Outline

* Identify stationary points: These are found by setting the first derivative of
the fitted response surface to 0
* Represent in canonical coordinates: Rewrite the stationary points using an
eigendecomposition.
* Characterize increasing / decreasing directions: The canonical representation
clarifies which directions in the factor space will increase or decrease the
response surface
  - Corollary: Distinguish minima, maxima, and saddlepoints

---

### Stationary Points

We can differentiate the second order model with respect to $x$, to determine
whether any factor combinations are stationary points.

.pull-left[
Equation:
$$\begin{align*}
y\left(x\right) &= x^{T}b + x^{T} B x + \epsilon
\end{align*}$$
]

.pull-right[
Derivative:
$$\begin{align*}
\nabla_{x}\hat{y}\left(x\right) &= \nabla_{x}\left[x^{T}\hat{b} + x^{T}\hat{B}x\right] \\
&= \hat{b} + 2\hat{B}x
\end{align*}$$

This is the multivariate analog of $\frac{\partial}{\partial x}\left[ax^2 + bx + c\right]$

]

---

### Stationary Points

.pull-left[
Setting the first derivative to zero and solving for $x$, we find that the
stationary point is,

\begin{align*}
x_{\ast} &= -\frac{1}{2}\hat{B}^{-1}\hat{b}.
\end{align*}
]

.pull-right[
Substituting into the formula for $y\left(x\right)$, we find that the response at the stationary point is,
\begin{align*}
\hat{y}_{\ast} &= \hat{b}^{T}x_{\ast} + x^{T}_{\ast}\hat{B}x_{\ast} \\
&= -\frac{1}{2}\hat{b}^{T}\hat{B}^{-1}\hat{b} + \frac{1}{4}\hat{b}^{T} \hat{B}^{-1} \hat{B} \hat{B}^{-1} \hat{b} \\
&= -\frac{1}{4}\hat{b}^{T}\hat{B}^{-1}\hat{b}
\end{align*}
]

The question is, does moving away from the stationary point $x^{\ast}$ increase
or decrease $y\left(x\right)$?

---

### Canonical Representation

.pull-left[
A key mathematical fact is that $\hat{B}$ can be written as 
\begin{align*}
\hat{B} &= U \Lambda U^{T}
\end{align*}
where $\Lambda$ is a diagonal matrix with nonnegative entries and the columns of
$U$ are orthogonal (at 90 degrees to one another).
]

.pull-right[
```{r, fig.cap = "Geometric representation of the eigendecomposition."}
include_graphics("https://uwmadison.box.com/shared/static/ngiy01l2mtvem1o9e6diwawhypgf3jst.png")
```
]

---

### Expansion of the Response Surface

* Let $w\left(x\right) = U^{T}\left(x - x_{\ast}\right)$. This gives the
coordinates of $x$ with respect to the canonical directions, with the origin
given by the stationary point.
* It's then possible to write the response surface as,

\begin{align*}
  \hat{y}\left(x\right) &= \hat{y}_{\ast} + w^T\left(x\right)\Lambda w\left(x\right) \\
  &= \hat{y}_{\ast} + \sum_{k = 1}^{K} \lambda_{k}w^{2}_{k}\left(x\right)
\end{align*}

---

### Canonical Representation

.pull-left[
* This gives an analog to the second derivative test
  - $w_k = 0 \implies$ stationary point
  - Moving in the direction $w_{k}$ changes the response by $\lambda_{k}$
* The sign of each term in the sum is determined by $\lambda_{k}$
  - All positive (negative) values $\implies$ local minimum (maximum)
  - Mix of positive and negative $\implies$ saddlepoint
]

.pull-right[
\begin{align*}
  \hat{y}\left(x\right) &= \hat{y}_{\ast} + w^T\left(x\right)\Lambda w\left(x\right) \\
  &= \hat{y}_{\ast} + \sum_{k = 1}^{K} \lambda_{k}w^{2}_{k}\left(x\right)
\end{align*}
]

---

### Code Implementation

```{r}
opts_chunk$set(echo = TRUE)
```


---

### Chemical Process Dataset

.pull-left[
We will work through example 11.1. Here, an experimenter is trying to optimize
yield as a function of reaction time and temperature. The current time /
temperature setting is at 35 minutes and 155 degrees. A $2^{2}$ factorial is run
with four center points.
]

.pull-right[
```{r}
library(readr)
library(dplyr)
chem <- read_csv("https://uwmadison.box.com/shared/static/4x9v5wtgu8w8i2kuzjdhtlhkj1tda701.csv") %>%
  group_split(seq) # split main from follow-up experiments
head(chem[[1]], 4)
```
]

---

### Chemical Process Dataset

.pull-left[
We will work through example 11.1. Here, an experimenter is trying to optimize
yield as a function of reaction time and temperature. The current time /
temperature setting is at 35 minutes and 155 degrees. A $2^{2}$ factorial is run
with four center points.
]

.pull-right[
```{r}
library(ggplot2)
p <- ggplot(chem[[1]]) +
  geom_point(
    aes(time, temp, col = yield),
    position = position_jitter(w = 0.5, h = 0.5),
    size = 3
  ) +
  coord_fixed() +
  scale_color_viridis_c()
p
```
]

---

### Coding the data

* `coded.data` codes the raw data. This interpolates the that are not at the
extremes.
* The syntax `~ (variable - center) / width` specifies where the design is
centered and the extreme points used in a given run
  - E.g., here, time was sampled at 30, 35, and 40

```{r}
library(rsm)
chem_coded <- coded.data(chem[[1]], time_coded ~ (time - 35) / 5, temp_coded ~ (temp - 155) / 5)
```

---

### First-Order Model

* The syntax for the `rsm` function is similar to `lm`, except we need to specify
the type of model to fit over sets of variables.
* `FO` fits a first order model, `SO` fits a second order model

```{r}
fit <- rsm(yield ~ FO(time_coded , temp_coded), chem_coded)
summary(fit)
```

---

### Interpretation

In our next experiment, we should increase time by $\Delta \times 4.44$ minutes
and temperature by $\Delta 2.30$ seconds for some step size $\Delta$.

```
Direction of steepest ascent (at radius 1):
time_coded temp_coded 
 0.8880276  0.4597901 

Corresponding increment in original units:
    time     temp 
4.440138 2.298951 
```

---

### `steepest`

The function `steepest` calculates these follow-up configurations automatically.

```{r}
steepest(fit, dist = seq(0, 2, 0.4))
```


---

### Subsequent Experiment

.pull-left[
In a follow-up experiment, we take more samples, since we believe we are close
to a maximizer.
]

.pull-right[
```{r}
chem <- read_csv("https://uwmadison.box.com/shared/static/nbaj1m8j7tuaqmznjlrsgbzyhp9k61i8.csv")
ggplot(chem) +
  geom_point(
    aes(time, temp, col = yield),
    position = position_jitter(w = 0.3, h = 0.3)
  ) +
  coord_fixed() +
  scale_color_viridis_c()
```
]

---

### Second Order Model

* We again code the data using the `coded.data` function
* We can fit a second order model using `SO`

```{r}
chem_coded <- coded.data(chem, time_coded ~ (time - 35) / 5, temp_coded ~ (temp - 155) / 5)
fit <- rsm(yield ~ SO(temp_coded, time_coded), chem_coded)
summary(fit)
```

---

### Stationary Points

We can get the stationary point in terms of the original units using the
`code2val` function.


```{r}
analysis <- canonical(fit)
stationary <- code2val(analysis$xs, codings = codings(chem_coded))
stationary
```

---

### Canonical Directions

* By adding the eigenvector directions, we can also see the directions that would
decrease the response surface the most quickly.
* Like the previous slide, we can code them using `code2val`

```{r}
w1 <- code2val(analysis$xs + analysis$eigen$vectors[, 1], codings = codings(chem_coded))
w2 <- code2val(analysis$xs + analysis$eigen$vectors[, 2], codings = codings(chem_coded))
w1
w2
```


---


### Interpretation

* Since both eigenvalues are negative, we are at a maximum
* The stationary point gives the optimal factor combination
* The eigenvectors are the matrix $U$

.pull-right[
```
Stationary point in original units:
     temp      time 
176.52923  86.94615 

Eigenanalysis:
eigen() decomposition
$values
[1] -0.9634986 -1.4142867

$vectors
                 [,1]       [,2]
temp_coded -0.9571122 -0.2897174
time_coded -0.2897174  0.9571122
```
]

---

### Second Order Model

We can visualize the fitted surface with the canonical directions overlaid.

```{r}
contour(fit, ~ time_coded + temp_coded, image = TRUE, asp = 1)
segments(stationary[2], stationary[1], w1[2], w1[1], col = "red")
segments(stationary[2], stationary[1], w2[2], w2[1], col = "red")
```

---

### Exercise

This exercise walks through Problem 11.6.

.pull-left[
The data below were collected in an experiment to optimize crystal growth as a
function of three variables $x_1, x_2$, and $x_3$. Large values of $y$ (yield in
grams) are desirable.  Fit a second order model and analyze the fitted surface.
Under what set of conditions is maximum growth achieved?
]

.pull-right[
```{r}
library(readr)
experiment <- read_csv("https://uwmadison.box.com/shared/static/lh9updl58a1xqaeunhumhrbrnv78630b.csv")
```
]

---

We can try breaking down the general problem statement,
(1) Use `rsm`, `SO`, and `canonical` to conduct a second order analysis.
  - Notice that the data are already coded
(2) Use the `Stationary points` part of the output to identify a candidate for the maximum.
(3) Look at the `$values` part of the output to determine whether the candidate is in fact a maximum (or if it is in fact a minimum or saddlepoint).
(4) Plot the fitted surface using `contour`.
(5) Interpret the resulting figure and check that it is consistent with the earlier numerical output.

---

### Solution (1)

```{r}
library(rsm)
fit <- rsm(y ~ SO(x_1, x_2, x_3), experiment)
canonical(fit)
```

---

### Solution (2)

Copying from the summary above, it seems like the point below is a potential
optimizer (it seems close to the origin).

```
Stationary point of response surface:
       x_1        x_2        x_3 
 0.2597353  0.1108581 -0.1400280 
```

---

### Solution (3)

Since all the eigenvalues are negative, we can conclude that the stationary
point is a maximum. Moving in any of the three eigenvector directions starting
from the stationary point would only reduce the response value.

```
$values
[1]  -3.079142  -8.952298 -13.764404
```

---

### Solution (4)

```{r}
contour(fit, ~ x_1 + x_2 + x_3, image = TRUE, asp = 1)
```

---

### Solution (5)

The brightest area is the maximizer. For $x_2$ and $x_3$, a value close to the
origin (midway between the low and high factor values) seems best. The surface
seems less sensitive to variation in the $x_1$ factor -- the response is high
across all both low and high values of $x_1$. The shape of the ellipses are
consistent with the eigenvectors. For example, for $x_3 = 0$ (the first plot),
the most rapid decrease is in the $\left(0.94, 0.21\right)$ direction.
